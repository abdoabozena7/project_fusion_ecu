{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fbd72d",
   "metadata": {},
   "source": [
    "# 06 â€“ Model Evaluation\n",
    "\n",
    "This notebook compares the performance of the trained models using various metrics and visualises the results with confusion matrices and ROC curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, roc_curve\n",
    "import joblib\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "models_dir = os.path.join(project_root, 'models')\n",
    "processed_dir = os.path.join(project_root, 'data', 'processed')\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv(os.path.join(processed_dir, 'X_test.csv'))\n",
    "y_test = pd.read_csv(os.path.join(processed_dir, 'y_test.csv')).squeeze()\n",
    "\n",
    "# Load models\n",
    "def load_model(name):\n",
    "    return joblib.load(os.path.join(models_dir, f\"{name}_model.pkl\"))\n",
    "\n",
    "model_names = ['LogisticRegression', 'RandomForest', 'GradientBoosting', 'XGBoost', 'Voting', 'Stacking']\n",
    "\n",
    "results = []\n",
    "roc_data = []\n",
    "\n",
    "for name in model_names:\n",
    "    model_path = os.path.join(models_dir, f\"{name}_model.pkl\") if name not in ['Voting', 'Stacking'] else os.path.join(models_dir, f\"{name}_model.pkl\")\n",
    "    if not os.path.exists(model_path):\n",
    "        continue\n",
    "    model = joblib.load(model_path)\n",
    "    preds = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "    results.append((name, acc, f1, auc))\n",
    "    fpr, tpr, _ = roc_curve(y_test, probas)\n",
    "    roc_data.append((name, fpr, tpr, auc))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1', 'AUC'])\n",
    "print(results_df.sort_values(by='AUC', ascending=False))\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, fpr, tpr, auc in roc_data:\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
