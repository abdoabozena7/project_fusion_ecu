{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f097d8",
   "metadata": {},
   "source": [
    "# 05 – Model Training and Ensemble Learning\n",
    "\n",
    "In this notebook we train multiple models on the preprocessed data and compare their performance.  We include logistic regression, random forest, gradient boosting and XGBoost.  We then build ensemble models such as stacking and voting using scikit‑learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5436e891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\projects\\Ai\\project_fusion_ecu\n",
      "Processed dir: d:\\projects\\Ai\\project_fusion_ecu\\data\\processed\n",
      "All required files exist.\n",
      "X_train: (304036, 14032)\n",
      "X_test: (40036, 14032)\n",
      "y_train: (304036,)\n",
      "y_test: (40036,)\n",
      "Preprocessor loaded (for deployment later).\n",
      "\n",
      "Training base model: LogisticRegression\n",
      "LogisticRegression – Accuracy: 0.5765, F1: 0.0988, AUC: 0.5378\n",
      "\n",
      "Training base model: RandomForest\n",
      "RandomForest – Accuracy: 0.9232, F1: 0.0339, AUC: 0.5147\n",
      "\n",
      "Training base model: GradientBoosting\n",
      "GradientBoosting – Accuracy: 0.8865, F1: 0.0646, AUC: 0.5019\n",
      "\n",
      "Training base model: XGBoost\n",
      "XGBoost – Accuracy: 0.9341, F1: 0.0287, AUC: 0.4978\n",
      "\n",
      "Base model performance:\n",
      "                Model  Accuracy        F1   ROC_AUC\n",
      "0  LogisticRegression  0.576456  0.098847  0.537782\n",
      "1        RandomForest  0.923219  0.033941  0.514692\n",
      "2    GradientBoosting  0.886477  0.064622  0.501899\n",
      "3             XGBoost  0.934134  0.028729  0.497844\n",
      "\n",
      "Training VotingClassifier...\n",
      "Voting – Accuracy: 0.9241, F1: 0.0368, AUC: 0.5321\n",
      "\n",
      "Training StackingClassifier...\n",
      "Stacking – Accuracy: 0.9210, F1: 0.0371, AUC: 0.5162\n",
      "\n",
      "All models performance (base + ensembles):\n",
      "                Model  Accuracy        F1   ROC_AUC\n",
      "0  LogisticRegression  0.576456  0.098847  0.537782\n",
      "4              Voting  0.924093  0.036767  0.532063\n",
      "5            Stacking  0.921021  0.037150  0.516240\n",
      "1        RandomForest  0.923219  0.033941  0.514692\n",
      "2    GradientBoosting  0.886477  0.064622  0.501899\n",
      "3             XGBoost  0.934134  0.028729  0.497844\n",
      "Saved LogisticRegression model to: d:\\projects\\Ai\\project_fusion_ecu\\models\\LogisticRegression_model.pkl\n",
      "Saved RandomForest model to: d:\\projects\\Ai\\project_fusion_ecu\\models\\RandomForest_model.pkl\n",
      "Saved GradientBoosting model to: d:\\projects\\Ai\\project_fusion_ecu\\models\\GradientBoosting_model.pkl\n",
      "Saved XGBoost model to: d:\\projects\\Ai\\project_fusion_ecu\\models\\XGBoost_model.pkl\n",
      "\n",
      "Saved ensembles:\n",
      " - d:\\projects\\Ai\\project_fusion_ecu\\models\\Voting_model.pkl\n",
      " - d:\\projects\\Ai\\project_fusion_ecu\\models\\Stacking_model.pkl\n",
      "\n",
      "[Model training and saving completed successfully.]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 0. Imports and configuration\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# ============================================\n",
    "# 1. Load NPZ data and labels\n",
    "# ============================================\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_dir = os.path.join(project_root, \"data\", \"processed\")\n",
    "models_dir = os.path.join(project_root, \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Processed dir:\", processed_dir)\n",
    "\n",
    "required = [\n",
    "    \"X_train_resampled.npz\",\n",
    "    \"X_test_transformed.npz\",\n",
    "    \"y_train_resampled.csv\",\n",
    "    \"y_test.csv\",\n",
    "    \"preprocessor.joblib\",\n",
    "]\n",
    "\n",
    "for fname in required:\n",
    "    path = os.path.join(processed_dir, fname)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Required file not found: {path}\")\n",
    "\n",
    "print(\"All required files exist.\")\n",
    "\n",
    "X_train = sparse.load_npz(os.path.join(processed_dir, \"X_train_resampled.npz\"))\n",
    "X_test = sparse.load_npz(os.path.join(processed_dir, \"X_test_transformed.npz\"))\n",
    "y_train = pd.read_csv(os.path.join(processed_dir, \"y_train_resampled.csv\")).squeeze()\n",
    "y_test = pd.read_csv(os.path.join(processed_dir, \"y_test.csv\")).squeeze()\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "preprocessor = joblib.load(os.path.join(processed_dir, \"preprocessor.joblib\"))\n",
    "print(\"Preprocessor loaded (for deployment later).\")\n",
    "\n",
    "# ============================================\n",
    "# 2. Define base models (input already preprocessed)\n",
    "# ============================================\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, n_jobs=-1),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=200, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# 3. Train and evaluate base models\n",
    "# ============================================\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining base model: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "\n",
    "    print(f\"{name} – Accuracy: {acc:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "    results.append((name, acc, f1, auc))\n",
    "    trained_models[name] = model\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"F1\", \"ROC_AUC\"])\n",
    "print(\"\\nBase model performance:\")\n",
    "print(results_df.sort_values(\"ROC_AUC\", ascending=False))\n",
    "\n",
    "# ============================================\n",
    "# 4. Voting ensemble (soft)\n",
    "# ============================================\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lr\", models[\"LogisticRegression\"]),\n",
    "        (\"rf\", models[\"RandomForest\"]),\n",
    "        (\"gb\", models[\"GradientBoosting\"]),\n",
    "        (\"xgb\", models[\"XGBoost\"]),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining VotingClassifier...\")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "preds_vot = voting_clf.predict(X_test)\n",
    "probas_vot = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_vot = accuracy_score(y_test, preds_vot)\n",
    "f1_vot = f1_score(y_test, preds_vot)\n",
    "auc_vot = roc_auc_score(y_test, probas_vot)\n",
    "\n",
    "print(f\"Voting – Accuracy: {acc_vot:.4f}, F1: {f1_vot:.4f}, AUC: {auc_vot:.4f}\")\n",
    "results.append((\"Voting\", acc_vot, f1_vot, auc_vot))\n",
    "\n",
    "# ============================================\n",
    "# 5. Stacking ensemble\n",
    "# ============================================\n",
    "\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"rf\", models[\"RandomForest\"]),\n",
    "        (\"gb\", models[\"GradientBoosting\"]),\n",
    "        (\"xgb\", models[\"XGBoost\"]),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=2000),\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining StackingClassifier...\")\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "preds_stack = stack_clf.predict(X_test)\n",
    "probas_stack = stack_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_stack = accuracy_score(y_test, preds_stack)\n",
    "f1_stack = f1_score(y_test, preds_stack)\n",
    "auc_stack = roc_auc_score(y_test, probas_stack)\n",
    "\n",
    "print(f\"Stacking – Accuracy: {acc_stack:.4f}, F1: {f1_stack:.4f}, AUC: {auc_stack:.4f}\")\n",
    "results.append((\"Stacking\", acc_stack, f1_stack, auc_stack))\n",
    "\n",
    "# ============================================\n",
    "# 6. Summary and saving models\n",
    "# ============================================\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"F1\", \"ROC_AUC\"])\n",
    "print(\"\\nAll models performance (base + ensembles):\")\n",
    "print(results_df.sort_values(\"ROC_AUC\", ascending=False))\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    path = os.path.join(models_dir, f\"{name}_model.pkl\")\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"Saved {name} model to: {path}\")\n",
    "\n",
    "voting_path = os.path.join(models_dir, \"Voting_model.pkl\")\n",
    "stacking_path = os.path.join(models_dir, \"Stacking_model.pkl\")\n",
    "joblib.dump(voting_clf, voting_path)\n",
    "joblib.dump(stack_clf, stacking_path)\n",
    "\n",
    "print(\"\\nSaved ensembles:\")\n",
    "print(\" -\", voting_path)\n",
    "print(\" -\", stacking_path)\n",
    "\n",
    "print(\"\\n[Model training and saving completed successfully.]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
