{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36b9bff",
   "metadata": {},
   "source": [
    "# 01 – Data Overview (PySpark)\n",
    "\n",
    "This notebook introduces the Taobao CTR dataset. We will load up to **500k rows** from each CSV file using PySpark (to handle large data volumes) and inspect the schema and basic statistics. \n",
    "\n",
    "**Note on Kaggle download**: If you have Kaggle API credentials set up, you can automatically download the dataset. Uncomment the lines in the code cell below and ensure your `kaggle.json` credentials file is in the correct location (`~/.kaggle`). Otherwise, place the CSV files manually into `data/raw`. \n",
    "\n",
    "* Data sources:\n",
    "  * `raw_sample.csv` – user impressions and clicks\n",
    "  * `ad_feature.csv` – advertisement metadata\n",
    "  * `user_profile.csv` – user demographics\n",
    "  * `behavior_log.csv` – user behaviour logs (page view, cart, favourite, purchase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f607956",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (368411133.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor key, fname in file_names.items():\u001b[39m\n                                         ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Start Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"CTR_Data_Overview\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", 200) \n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\") # Reduce log verbosity\n",
    "print(\"Spark version:\", spark.version)\n",
    "\n",
    "# Define project and data paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "raw_dir = os.path.join(project_root, \"data\", \"raw\")\n",
    "print(\"Raw data directory:\", raw_dir)\n",
    "\n",
    "# Expected file names\n",
    "file_names = {\n",
    "    \"raw_sample\": \"raw_sample.csv\",\n",
    "    \"ad_feature\": \"ad_feature.csv\",\n",
    "    \"user_profile\": \"user_profile.csv\",\n",
    "    \"behavior_log\": \"behavior_log.csv\",\n",
    "}\n",
    "\n",
    "# Verify that files exist\n",
    "missing = []\n",
    "for key, fname in file_names.items():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
