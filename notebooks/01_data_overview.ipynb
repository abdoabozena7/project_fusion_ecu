{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36b9bff",
   "metadata": {},
   "source": [
    "# 01 – Data Overview (PySpark)\n",
    "\n",
    "This notebook introduces the Taobao CTR dataset. We will load up to **500k rows** from each CSV file using PySpark (to handle large data volumes) and inspect the schema and basic statistics. \n",
    "\n",
    "**Note on Kaggle download**: If you have Kaggle API credentials set up, you can automatically download the dataset. Uncomment the lines in the code cell below and ensure your `kaggle.json` credentials file is in the correct location (`~/.kaggle`). Otherwise, place the CSV files manually into `data/raw`. \n",
    "\n",
    "* Data sources:\n",
    "  * `raw_sample.csv` – user impressions and clicks\n",
    "  * `ad_feature.csv` – advertisement metadata\n",
    "  * `user_profile.csv` – user demographics\n",
    "  * `behavior_log.csv` – user behaviour logs (page view, cart, favourite, purchase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f607956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n",
      "Project root: d:\\projects\\Ai\\project_fusion_ecu\n",
      "Raw data directory: d:\\projects\\Ai\\project_fusion_ecu\\data\\raw\n",
      "\n",
      "======================================================================\n",
      "DATASET: raw_sample\n",
      "======================================================================\n",
      "Rows: 100,836 | Columns: 6\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- adgroup_id: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- time_stamp: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- clk: integer (nullable = true)\n",
      "\n",
      "\n",
      "Sample (5 rows):\n",
      "+----+----------+------+----------+-----+---+\n",
      "|user|adgroup_id|rating|time_stamp|label|clk|\n",
      "+----+----------+------+----------+-----+---+\n",
      "|1   |1         |4.0   |964982703 |1    |1  |\n",
      "|1   |3         |4.0   |964981247 |1    |1  |\n",
      "|1   |6         |4.0   |964982224 |1    |1  |\n",
      "|1   |47        |5.0   |964983815 |1    |1  |\n",
      "|1   |50        |5.0   |964982931 |1    |1  |\n",
      "+----+----------+------+----------+-----+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "Top missing columns (up to 20):\n",
      "No missing values detected (null/empty).\n",
      "\n",
      "======================================================================\n",
      "DATASET: ad_feature\n",
      "======================================================================\n",
      "Rows: 9,742 | Columns: 3\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- adgroup_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "\n",
      "Sample (5 rows):\n",
      "+----------+----------------------------------+-------------------------------------------+\n",
      "|adgroup_id|title                             |genres                                     |\n",
      "+----------+----------------------------------+-------------------------------------------+\n",
      "|1         |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2         |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3         |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4         |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5         |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "+----------+----------------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Top missing columns (up to 20):\n",
      "No missing values detected (null/empty).\n",
      "\n",
      "======================================================================\n",
      "DATASET: user_profile\n",
      "======================================================================\n",
      "Rows: 610 | Columns: 5\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- num_ratings: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- std_rating: double (nullable = true)\n",
      " |-- num_tags: integer (nullable = true)\n",
      "\n",
      "\n",
      "Sample (5 rows):\n",
      "+----+-----------+------------------+------------------+--------+\n",
      "|user|num_ratings|avg_rating        |std_rating        |num_tags|\n",
      "+----+-----------+------------------+------------------+--------+\n",
      "|1   |232        |4.366379310344827 |0.8000480467733436|0       |\n",
      "|2   |29         |3.9482758620689653|0.8056145345791144|9       |\n",
      "|3   |39         |2.4358974358974357|2.0906417019771424|0       |\n",
      "|4   |216        |3.5555555555555554|1.3142038589753633|0       |\n",
      "|5   |44         |3.6363636363636362|0.9904405665441197|0       |\n",
      "+----+-----------+------------------+------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Top missing columns (up to 20):\n",
      "No missing values detected (null/empty).\n",
      "\n",
      "======================================================================\n",
      "DATASET: behavior_log\n",
      "======================================================================\n",
      "Rows: 3,683 | Columns: 4\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- adgroup_id: integer (nullable = true)\n",
      " |-- btag: string (nullable = true)\n",
      " |-- time_stamp: integer (nullable = true)\n",
      "\n",
      "\n",
      "Sample (5 rows):\n",
      "+----+----------+---------------+----------+\n",
      "|user|adgroup_id|btag           |time_stamp|\n",
      "+----+----------+---------------+----------+\n",
      "|2   |60756     |funny          |1445714994|\n",
      "|2   |60756     |Highly quotable|1445714996|\n",
      "|2   |60756     |will ferrell   |1445714992|\n",
      "|2   |89774     |Boxing story   |1445715207|\n",
      "|2   |89774     |MMA            |1445715200|\n",
      "+----+----------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Top missing columns (up to 20):\n",
      "No missing values detected (null/empty).\n",
      "\n",
      "✅ Done. All datasets loaded and profiled.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "\n",
    "# 1) Start Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"CTR_Data_Overview\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", 200)\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark version:\", spark.version)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    here = os.path.dirname(os.path.abspath(__file__))\n",
    "    project_root = os.path.abspath(os.path.join(here, \"..\"))\n",
    "except NameError:\n",
    "    # Fallback for notebooks / interactive\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "raw_dir = os.path.join(project_root, \"data\", \"raw\")\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Raw data directory:\", raw_dir)\n",
    "\n",
    "file_names = {\n",
    "    \"raw_sample\": \"raw_sample.csv\",\n",
    "    \"ad_feature\": \"ad_feature.csv\",\n",
    "    \"user_profile\": \"user_profile.csv\",\n",
    "    \"behavior_log\": \"behavior_log.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "missing = []\n",
    "paths = {}\n",
    "\n",
    "for key, fname in file_names.items():\n",
    "    fpath = os.path.join(raw_dir, fname)\n",
    "    paths[key] = fpath\n",
    "    if not os.path.isfile(fpath):\n",
    "        missing.append(fpath)\n",
    "\n",
    "if missing:\n",
    "    print(\"\\nERROR: Missing required files:\")\n",
    "    for p in missing:\n",
    "        print(\" -\", p)\n",
    "    raise FileNotFoundError(\"Some required CSV files are missing. Check your data/raw folder.\")\n",
    "\n",
    "def read_csv_safe(path: str):\n",
    "\n",
    "    return (\n",
    "        spark.read\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .option(\"mode\", \"DROPMALFORMED\")\n",
    "            .csv(path)\n",
    "    )\n",
    "\n",
    "\n",
    "def overview_df(df, name: str, show_n: int = 5):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"DATASET: {name}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Row count (action)\n",
    "    n_rows = df.count()\n",
    "    n_cols = len(df.columns)\n",
    "    print(f\"Rows: {n_rows:,} | Columns: {n_cols}\")\n",
    "\n",
    "    # Schema\n",
    "    print(\"\\nSchema:\")\n",
    "    df.printSchema()\n",
    "\n",
    "    # Sample\n",
    "    print(f\"\\nSample ({show_n} rows):\")\n",
    "    df.show(show_n, truncate=False)\n",
    "\n",
    "    # Missing values overview (for each column)\n",
    "    # Note: For large tables, this is still OK but does one pass.\n",
    "    miss_exprs = [\n",
    "        F.sum(\n",
    "            F.when(F.col(c).isNull() | (F.trim(F.col(c).cast(\"string\")) == \"\"), 1).otherwise(0)\n",
    "        ).alias(c)\n",
    "        for c in df.columns\n",
    "    ]\n",
    "    miss_row = df.select(miss_exprs).collect()[0].asDict()\n",
    "\n",
    "    # Print top missing columns\n",
    "    miss_sorted = sorted(miss_row.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_missing = [(c, m) for c, m in miss_sorted if m and m > 0][:20]\n",
    "\n",
    "    print(\"\\nTop missing columns (up to 20):\")\n",
    "    if not top_missing:\n",
    "        print(\"No missing values detected (null/empty).\")\n",
    "    else:\n",
    "        for c, m in top_missing:\n",
    "            pct = (m / n_rows * 100.0) if n_rows > 0 else 0.0\n",
    "            print(f\"- {c}: {m:,} ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "df_raw_sample   = read_csv_safe(paths[\"raw_sample\"])\n",
    "df_ad_feature   = read_csv_safe(paths[\"ad_feature\"])\n",
    "df_user_profile = read_csv_safe(paths[\"user_profile\"])\n",
    "df_behavior_log = read_csv_safe(paths[\"behavior_log\"])\n",
    "\n",
    "\n",
    "overview_df(df_raw_sample,   \"raw_sample\")\n",
    "overview_df(df_ad_feature,   \"ad_feature\")\n",
    "overview_df(df_user_profile, \"user_profile\")\n",
    "overview_df(df_behavior_log, \"behavior_log\")\n",
    "\n",
    "\n",
    "print(\"\\n Done. All datasets loaded and profiled.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
